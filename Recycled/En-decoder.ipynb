{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxyC7vwCOhvm"
      },
      "source": [
        "### encoding\n",
        "\n",
        "The other way around: Given a string, what are the tokens?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfOyfLVYOhvm",
        "outputId": "2952733e-273f-4015-e4fc-d5ec134b72f1"
      },
      "outputs": [],
      "source": [
        "def encode_simple(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = simple_get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = simple_merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "def encode(texts):\n",
        "    encoded_texts = []\n",
        "    for text in texts:\n",
        "        # Convert text to UTF-8 bytes and then to a list of integers\n",
        "        tokens = list(text.encode(\"utf-8\"))\n",
        "        while len(tokens) >= 2:\n",
        "            stats = simple_get_stats(tokens)\n",
        "            pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "            if pair not in merges:\n",
        "                break  # Nothing else can be merged\n",
        "            idx = merges[pair]\n",
        "            tokens = simple_merge(tokens, pair, idx)\n",
        "        encoded_texts.append(tokens)\n",
        "    return encoded_texts\n",
        "\n",
        "\n",
        "def decode_simple(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\".\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "def decode(ids):\n",
        "    text_concatenate = \"\"\n",
        "    for word in ids:\n",
        "        # Convert list of integer IDs into bytes using the vocab dictionary\n",
        "        tokens = b\".\".join(vocab[idx] for idx in word)\n",
        "        # Decode bytes to a string, replacing errors with a placeholder\n",
        "        text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "        # Concatenate the decoded text with a space\n",
        "        text_concatenate += text + \".\"\n",
        "    return text_concatenate.strip()  # Remove trailing space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[220, 152], [220, 161, 220, 160, 220, 159, 220, 144]]\n",
            "[[257], [1196], [836], [5562], [267], [367], [5563], [267], [261, 647, 280], [568], [333], [4677], [267], [289], [307, 1596], [267], [770], [333], [856], [553], [1974], [819], [294, 2156], [5564]]\n",
            "ܘ.ܡܠܟܐ. ܕܘܝܕ. ܣܐܒ. ܘ.ܥܠ. ܒܫܢܝܐ. ܘ.ܡ.ܟܣ.ܝܢ. ܗܘܘ. ܠܗ. ܒܠܒܘܫܐ. ܘ.ܠܐ. ܫ.ܚܢ. ܘ.ܐܡܪܘ. ܠܗ. ܥܒܕܘܗܝ. ܗܐ. ܥܒܕܝܟ. ܩܕܡܝܟ. ܢ.ܒܥܘܢ. ܠܡܪܢ.\n"
          ]
        }
      ],
      "source": [
        "text = \"ܘܡܠܟܐ ܕܘܝܕ ܣܐܒ ܘܥܠ ܒܫܢܝܐ ܘܡܟܣܝܢ ܗܘܘ ܠܗ ܒܠܒܘܫܐ ܘܠܐ ܫܚܢ ܘܐܡܪܘ ܠܗ ܥܒܕܘܗܝ ܗܐ ܥܒܕܝܟ ܩܕܡܝܟ ܢܒܥܘܢ ܠܡܪܢ\"\n",
        "\n",
        "text_words = re.findall(pattern, text) # devide the text into words according to gpt2pat pattern\n",
        "\n",
        "words_tokens = []\n",
        "for i in text_words:\n",
        "    token_word = i.encode(\"utf-8\")\n",
        "    token = list(map(int, token_word))\n",
        "    words_tokens.append(token)\n",
        "print(words_tokens[:2])\n",
        "\n",
        "text_encoded = encode(text_words)\n",
        "print (text_encoded)\n",
        "text_decoded = decode(text_encoded)\n",
        "print (text_decoded)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

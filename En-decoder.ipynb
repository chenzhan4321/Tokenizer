{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "import ast\n",
        "import json\n",
        "import regex as re\n",
        "\n",
        "pattern = re.compile(r\"\"\" ?ܘ(?=\\p{L}+)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "with open('merges_6000.json', 'r') as f:\n",
        "    merges_converted = json.load(f)\n",
        "\n",
        "with open('vocabulary_6000.json', 'r') as f:\n",
        "    vocab_converted = json.load(f)\n",
        "\n",
        "def convert_keys_and_values(d):\n",
        "    converted_dict = {}\n",
        "    for k, v in d.items():\n",
        "        \n",
        "        \n",
        "        # Convert string representation of tuple back to tuple\n",
        "        # Convert string representation of integers back to integers\n",
        "        if k.startswith('(') and k.endswith(')'):\n",
        "            m = eval(k)  \n",
        "        elif k.isdigit():\n",
        "            m = int(k)\n",
        "        else:\n",
        "            m = k    \n",
        "            \n",
        "        \n",
        "        # Convert string values back to bytes if necessary (assuming some indication that it was a byte string)\n",
        "        # This example assumes no special encoding for bytes, but you can customize this as needed.\n",
        "        byte_value = v.encode('utf-8') if isinstance(v, str) else v\n",
        "        \n",
        "        converted_dict[m] = byte_value\n",
        "        \n",
        "        \n",
        "\n",
        "    return converted_dict\n",
        "\n",
        "vocab = convert_keys_and_values(vocab_converted)\n",
        "merges = convert_keys_and_values(merges_converted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPEjcKJ3Ohvh",
        "outputId": "e009b149-7b93-4bdd-fc5f-2c18e995fa19"
      },
      "outputs": [],
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for id in ids:    \n",
        "        for pair in zip(id, id[1:]): # Pythonic way to iterate consecutive elements\n",
        "            if pair[1] != 220:  # Check to avoid pairs ending with 220\n",
        "                counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "\n",
        "def simple_get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        if pair[1] != ord(' ') and pair[1] != 220:  # Check to avoid pairs ending with 220\n",
        "            counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "#top_pair = max(stats, key=stats.get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUV5pr3iOhvi",
        "outputId": "10af5b63-b47f-4daf-d01b-bb1dc4451e43"
      },
      "outputs": [],
      "source": [
        "def merge(ids, pair, idx):\n",
        "  # in the list of ints (ids), replace all consecutive occurences of pair with the new token idx\n",
        "  newids = []\n",
        "  for sublist in ids:\n",
        "        i = 0\n",
        "        new_sublist = []\n",
        "        while i < len(sublist):\n",
        "            # if we are not at the very last position AND the pair matches, replace it\n",
        "            if i < len(sublist) - 1 and sublist[i] == pair[0] and sublist[i + 1] == pair[1]:\n",
        "                new_sublist.append(idx)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_sublist.append(sublist[i])\n",
        "                i += 1\n",
        "        newids.append(new_sublist)\n",
        "  return newids\n",
        "\n",
        "def simple_merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "\n",
        "def length(ids):\n",
        "    return sum(len(id) for id in ids)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxyC7vwCOhvm"
      },
      "source": [
        "### encoding\n",
        "\n",
        "The other way around: Given a string, what are the tokens?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfOyfLVYOhvm",
        "outputId": "2952733e-273f-4015-e4fc-d5ec134b72f1"
      },
      "outputs": [],
      "source": [
        "def encode_simple(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = simple_get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = simple_merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "def encode(texts):\n",
        "    encoded_texts = []\n",
        "    for text in texts:\n",
        "        # Convert text to UTF-8 bytes and then to a list of integers\n",
        "        tokens = list(text.encode(\"utf-8\"))\n",
        "        while len(tokens) >= 2:\n",
        "            stats = simple_get_stats(tokens)\n",
        "            pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "            if pair not in merges:\n",
        "                break  # Nothing else can be merged\n",
        "            idx = merges[pair]\n",
        "            tokens = simple_merge(tokens, pair, idx)\n",
        "        encoded_texts.append(tokens)\n",
        "    return encoded_texts\n",
        "\n",
        "\n",
        "def decode_simple(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\".\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "def decode(ids):\n",
        "    text_concatenate = \"\"\n",
        "    for word in ids:\n",
        "        # Convert list of integer IDs into bytes using the vocab dictionary\n",
        "        tokens = b\".\".join(vocab[idx] for idx in word)\n",
        "        # Decode bytes to a string, replacing errors with a placeholder\n",
        "        text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "        # Concatenate the decoded text with a space\n",
        "        text_concatenate += text + \".\"\n",
        "    return text_concatenate.strip()  # Remove trailing space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[220, 152], [220, 161, 220, 160, 220, 159, 220, 144]]\n",
            "[[257], [1196], [836], [5562], [267], [367], [5563], [267], [261, 647, 280], [568], [333], [4677], [267], [289], [307, 1596], [267], [770], [333], [856], [553], [1974], [819], [294, 2156], [5564]]\n",
            "ܘ.ܡܠܟܐ. ܕܘܝܕ. ܣܐܒ. ܘ.ܥܠ. ܒܫܢܝܐ. ܘ.ܡ.ܟܣ.ܝܢ. ܗܘܘ. ܠܗ. ܒܠܒܘܫܐ. ܘ.ܠܐ. ܫ.ܚܢ. ܘ.ܐܡܪܘ. ܠܗ. ܥܒܕܘܗܝ. ܗܐ. ܥܒܕܝܟ. ܩܕܡܝܟ. ܢ.ܒܥܘܢ. ܠܡܪܢ.\n"
          ]
        }
      ],
      "source": [
        "text = \"ܘܡܠܟܐ ܕܘܝܕ ܣܐܒ ܘܥܠ ܒܫܢܝܐ ܘܡܟܣܝܢ ܗܘܘ ܠܗ ܒܠܒܘܫܐ ܘܠܐ ܫܚܢ ܘܐܡܪܘ ܠܗ ܥܒܕܘܗܝ ܗܐ ܥܒܕܝܟ ܩܕܡܝܟ ܢܒܥܘܢ ܠܡܪܢ\"\n",
        "\n",
        "text_words = re.findall(pattern, text) # devide the text into words according to gpt2pat pattern\n",
        "\n",
        "words_tokens = []\n",
        "for i in text_words:\n",
        "    token_word = i.encode(\"utf-8\")\n",
        "    token = list(map(int, token_word))\n",
        "    words_tokens.append(token)\n",
        "print(words_tokens[:2])\n",
        "\n",
        "text_encoded = encode(text_words)\n",
        "print (text_encoded)\n",
        "text_decoded = decode(text_encoded)\n",
        "print (text_decoded)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
